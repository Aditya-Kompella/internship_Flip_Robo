{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "headersList = soup.find_all('span',class_=\"mw-headline\")\n",
    "#print(headersList)\n",
    "headersArr = []\n",
    "for i in headersList:\n",
    "    headersArr.append(i.text)\n",
    "headersArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB rating</th>\n",
       "      <th>Year Of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name IMDB rating Year Of Release\n",
       "0            The Shawshank Redemption         9.3            1994\n",
       "1                       The Godfather         9.2            1972\n",
       "2                     The Dark Knight         9.0            2008\n",
       "3              The Godfather: Part II         9.0            1974\n",
       "4                        12 Angry Men         9.0            1957\n",
       "..                                ...         ...             ...\n",
       "95                 North by Northwest         8.3            1959\n",
       "96                            Vertigo         8.3            1958\n",
       "97                Singin' in the Rain         8.3            1952\n",
       "98                       Citizen Kane         8.3            1941\n",
       "99  M - Eine Stadt sucht einen Mörder         8.3            1931\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 movies’ data \n",
    "#(i.e. Name, IMDB rating, Year of release) and make data frame.\n",
    "def getTheListOfIMDB(link):\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    ratingsList = soup.find_all('div',class_=\"inline-block ratings-imdb-rating\")\n",
    "    ratingsArr = []\n",
    "    for i in ratingsList:\n",
    "        ratingsArr.append(i.text.replace('\\n',''))\n",
    "    titlesList = soup.find_all('h3',class_=\"lister-item-header\")\n",
    "    titlesArr = []\n",
    "    for i in titlesList:\n",
    "        title = i.text.replace('\\n','')\n",
    "        dotElement = title.find('.')\n",
    "        titlesArr.append(title[dotElement+1:-6])\n",
    "    yearsList = soup.find_all('span',class_=\"lister-item-year text-muted unbold\")\n",
    "    yearsArr = []\n",
    "    for i in yearsList:\n",
    "        yearStr = i.text.replace('\\n','')\n",
    "        yearsArr.append(yearStr[1:-1])\n",
    "    retData = pd.DataFrame({})\n",
    "    retData['Name'] = titlesArr\n",
    "    retData['IMDB rating'] = ratingsArr\n",
    "    retData['Year Of Release'] = yearsArr\n",
    "    return retData\n",
    "list1To50 = getTheListOfIMDB('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')\n",
    "list51To100 = getTheListOfIMDB('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt')\n",
    "finalAnswer = pd.concat([list1To50, list51To100],ignore_index=True)\n",
    "finalAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PatherPanchali</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PariyerumPerumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnbeSivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AndazApnaApna</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Uri:TheSurgicalStrike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PK</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lucia</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name IMDB rating Year of release\n",
       "0          PatherPanchali         8.5            1955\n",
       "1                 Nayakan         8.5            1987\n",
       "2        PariyerumPerumal         8.5            2018\n",
       "3               AnbeSivam         8.5            2003\n",
       "4                 Golmaal         8.5            1979\n",
       "..                    ...         ...             ...\n",
       "95          AndazApnaApna         8.1            1994\n",
       "96              Virumandi         8.1            2004\n",
       "97  Uri:TheSurgicalStrike         8.1            2018\n",
       "98                     PK         8.1            2014\n",
       "99                  Lucia         8.1            2013\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 Indian movies’ data \n",
    "#(i.e. Name, IMDB rating, Year of release) and make data frame.\n",
    "link = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titlesList = soup.find_all('td',class_=\"titleColumn\",limit = 100)\n",
    "titlesArr = []\n",
    "yearArr = []\n",
    "for i in titlesList:\n",
    "    title = i.text.replace('\\n','').replace(' ','')\n",
    "    dotElement = title.find('.')\n",
    "    yearArr.append(title[-5:-1])\n",
    "    titlesArr.append(title[dotElement+1:-6])\n",
    "ratingsList = soup.find_all('td',class_=\"ratingColumn imdbRating\",limit = 100)\n",
    "ratingArr = []\n",
    "for i in ratingsList:\n",
    "    ratingArr.append(i.text.replace('\\n',''))\n",
    "ratingArr\n",
    "retFrame = pd.DataFrame({})\n",
    "retFrame['Name'] = titlesArr\n",
    "retFrame['IMDB rating'] = ratingArr\n",
    "retFrame['Year of release'] = yearArr\n",
    "retFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>2,438</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>1,876</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points                           Rating\n",
       "0   New Zealand      17  2,054                              121\n",
       "1     Australia      25  2,945                              118\n",
       "2         India      29  3,344                              115\n",
       "3       England      27  3,100                              115\n",
       "4  South Africa      20  2,137                              107\n",
       "5      Pakistan      24  2,323                               97\n",
       "6    Bangladesh      27  2,438                               90\n",
       "7   West Indies      27  2,222                               82\n",
       "8     Sri Lanka      24  1,876                               78\n",
       "9   Afghanistan      17  1,054                               62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "link = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titlesList = soup.find_all('tr',class_=\"rankings-block__banner\",limit = 10)\n",
    "titlesArr = []\n",
    "matchesArr = []\n",
    "pointsArr = []\n",
    "ratingArr = []\n",
    "for i in titlesList:\n",
    "    teamData = i.text\n",
    "    leaderArr = list(filter(None,teamData.split(\"\\n\")))\n",
    "    titlesArr.append(leaderArr[1])\n",
    "    matchesArr.append(leaderArr[3])\n",
    "    pointsArr.append(leaderArr[4])\n",
    "    ratingArr.append(leaderArr[5])\n",
    "runnersList = soup.find_all('tr',class_=\"table-body\",limit = 9)\n",
    "for i in runnersList:\n",
    "    teamData = i.text\n",
    "    runnersArr = list(filter(None,teamData.split(\"\\n\")))\n",
    "    titlesArr.append(runnersArr[1])\n",
    "    matchesArr.append(runnersArr[3])\n",
    "    pointsArr.append(runnersArr[4])\n",
    "    ratingArr.append(runnersArr[5])\n",
    "\n",
    "menTeamFrame = pd.DataFrame({})\n",
    "menTeamFrame['Teams'] = titlesArr\n",
    "menTeamFrame['Matches'] = matchesArr\n",
    "menTeamFrame['Points'] = pointsArr\n",
    "menTeamFrame['Rating'] = ratingArr\n",
    "menTeamFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0        Trent Boult   NZ    737\n",
       "1       Mehedi Hasan  BAN    713\n",
       "2   Mujeeb Ur Rahman  AFG    708\n",
       "3         Matt Henry   NZ    691\n",
       "4     Jasprit Bumrah  IND    690\n",
       "5      Kagiso Rabada   SA    666\n",
       "6       Chris Woakes  ENG    665\n",
       "7     Josh Hazlewood  AUS    660\n",
       "8        Pat Cummins  AUS    646\n",
       "9  Mustafizur Rahman  BAN    645"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "#iii) Top 10 ODI bowlers along with the records of their team and rating\n",
    "link = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "leaderBatsmansList = soup.find_all('div',class_=\"rankings-block__banner--name\",limit = 10)\n",
    "leaderNationsList = soup.find_all('div',class_=\"rankings-block__banner--nationality\",limit = 10)\n",
    "storeLeaderNationArr = []\n",
    "storeLeaderArr =[]\n",
    "storeLeaderRatingArr =[]\n",
    "for i in leaderBatsmansList:\n",
    "    storeLeaderArr.append(i.text.replace('\\n',''))\n",
    "for i in leaderNationsList:\n",
    "    nationRating = i.text.replace('\\n','').replace(' ','')\n",
    "    storeLeaderRatingArr.append(nationRating[-3:])\n",
    "    storeLeaderNationArr.append(nationRating[:-3])\n",
    "batsmenNameArr = [storeLeaderArr[0]]\n",
    "batsmenTeamArr = [storeLeaderNationArr[0]]\n",
    "batsmenRatingArr = [storeLeaderRatingArr[0]]\n",
    "bowlerNameArr = [storeLeaderArr[1]]\n",
    "bowlerTeamArr = [storeLeaderNationArr[1]]\n",
    "bowlerRatingArr = [storeLeaderRatingArr[1]]\n",
    "runnersList = soup.find_all('td',class_=\"table-body__cell name\",limit=18)\n",
    "listArr = []\n",
    "for i in runnersList:\n",
    "    listArr.append(i.text.replace('\\n',''))\n",
    "batsmensList=listArr[:9]\n",
    "for i in batsmensList:\n",
    "    batsmenNameArr.append(i)\n",
    "# batsmenNameArr\n",
    "bowlersList=listArr[9:18]\n",
    "for i in bowlersList:\n",
    "    bowlerNameArr.append(i)\n",
    "runnercountryHtml = soup.find_all('span',class_=\"table-body__logo-text\",limit=18)\n",
    "teamsList = []\n",
    "for i in runnercountryHtml:\n",
    "    teamsList.append(i.text)\n",
    "batsmenTeamsList=teamsList[:9]\n",
    "for i in batsmenTeamsList:\n",
    "    batsmenTeamArr.append(i)\n",
    "# batsmenNameArr\n",
    "bowlersTeamsList=teamsList[9:18]\n",
    "for i in bowlersTeamsList:\n",
    "    bowlerTeamArr.append(i)\n",
    "runnerRatingHtml = soup.find_all('td',class_=\"table-body__cell u-text-right rating\",limit=18)\n",
    "runnerRatingList = []\n",
    "for i in runnerRatingHtml:\n",
    "    runnerRatingList.append(i.text)\n",
    "batsmenRatingList=runnerRatingList[:9]\n",
    "for i in batsmenRatingList:\n",
    "    batsmenRatingArr.append(i)\n",
    "# batsmenNameArr\n",
    "bowlersRatingList=runnerRatingList[9:18]\n",
    "for i in bowlersRatingList:\n",
    "    bowlerRatingArr.append(i)\n",
    "batsmenFrame = pd.DataFrame({})\n",
    "bowlerFrame = pd.DataFrame({})\n",
    "batsmenFrame['Player'] = batsmenNameArr\n",
    "batsmenFrame['Team'] = batsmenTeamArr\n",
    "batsmenFrame['Rating'] = batsmenRatingArr\n",
    "bowlerFrame['Player'] = bowlerNameArr\n",
    "bowlerFrame['Team'] = bowlerTeamArr\n",
    "bowlerFrame['Rating'] = bowlerRatingArr\n",
    "bowlerFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points                           Rating\n",
       "0     Australia      18  2,955                              164\n",
       "1  South Africa      24  2,828                              118\n",
       "2       England      17  1,993                              117\n",
       "3         India      20  2,226                              111\n",
       "4   New Zealand      21  1,947                               93\n",
       "5   West Indies      12  1,025                               85\n",
       "6      Pakistan      15  1,101                               73\n",
       "7    Bangladesh       5    306                               61\n",
       "8     Sri Lanka      11    519                               47\n",
       "9       Ireland       2     25                               13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "# i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "link = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titlesList = soup.find_all('tr',class_=\"rankings-block__banner\",limit = 10)\n",
    "titlesArr = []\n",
    "matchesArr = []\n",
    "pointsArr = []\n",
    "ratingArr = []\n",
    "for i in titlesList:\n",
    "    teamData = i.text\n",
    "    leaderArr = list(filter(None,teamData.split(\"\\n\")))\n",
    "    titlesArr.append(leaderArr[1])\n",
    "    matchesArr.append(leaderArr[3])\n",
    "    pointsArr.append(leaderArr[4])\n",
    "    ratingArr.append(leaderArr[5])\n",
    "runnersList = soup.find_all('tr',class_=\"table-body\",limit = 9)\n",
    "for i in runnersList:\n",
    "    teamData = i.text\n",
    "    runnersArr = list(filter(None,teamData.split(\"\\n\")))\n",
    "    titlesArr.append(runnersArr[1])\n",
    "    matchesArr.append(runnersArr[3])\n",
    "    pointsArr.append(runnersArr[4])\n",
    "    ratingArr.append(runnersArr[5])\n",
    "\n",
    "womenTeamFrame = pd.DataFrame({})\n",
    "womenTeamFrame['Teams'] = titlesArr\n",
    "womenTeamFrame['Matches'] = matchesArr\n",
    "womenTeamFrame['Points'] = pointsArr\n",
    "womenTeamFrame['Rating'] = ratingArr\n",
    "womenTeamFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0     Tammy Beaumont  ENG    765\n",
       "1        Lizelle Lee   SA    758\n",
       "2       Alyssa Healy  AUS    756\n",
       "3    Stafanie Taylor   WI    746\n",
       "4        Meg Lanning  AUS    723\n",
       "5  Amy Satterthwaite   NZ    715\n",
       "6    Smriti Mandhana  IND    710\n",
       "7        Mithali Raj  IND    709\n",
       "8     Natalie Sciver  ENG    685\n",
       "9    Laura Wolvaardt   SA    683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ii) Top 10 ODI Batsmen in women along with the records of their team and rating.\n",
    "#iii) Top 10 ODI bowlers along with the records of their team and rating\n",
    "link = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "leaderBatsmansList = soup.find_all('div',class_=\"rankings-block__banner--name\",limit = 10)\n",
    "leaderNationsList = soup.find_all('div',class_=\"rankings-block__banner--nationality\",limit = 10)\n",
    "storeLeaderNationArr = []\n",
    "storeLeaderArr =[]\n",
    "storeLeaderRatingArr =[]\n",
    "for i in leaderBatsmansList:\n",
    "    storeLeaderArr.append(i.text.replace('\\n',''))\n",
    "for i in leaderNationsList:\n",
    "    nationRating = i.text.replace('\\n','').replace(' ','')\n",
    "    storeLeaderRatingArr.append(nationRating[-3:])\n",
    "    storeLeaderNationArr.append(nationRating[:-3])\n",
    "batsmenNameArr = [storeLeaderArr[0]]\n",
    "batsmenTeamArr = [storeLeaderNationArr[0]]\n",
    "batsmenRatingArr = [storeLeaderRatingArr[0]]\n",
    "bowlerNameArr = [storeLeaderArr[1]]\n",
    "bowlerTeamArr = [storeLeaderNationArr[1]]\n",
    "bowlerRatingArr = [storeLeaderRatingArr[1]]\n",
    "runnersList = soup.find_all('td',class_=\"table-body__cell name\",limit=18)\n",
    "listArr = []\n",
    "for i in runnersList:\n",
    "    listArr.append(i.text.replace('\\n',''))\n",
    "batsmensList=listArr[:9]\n",
    "for i in batsmensList:\n",
    "    batsmenNameArr.append(i)\n",
    "# batsmenNameArr\n",
    "bowlersList=listArr[9:18]\n",
    "for i in bowlersList:\n",
    "    bowlerNameArr.append(i)\n",
    "runnercountryHtml = soup.find_all('span',class_=\"table-body__logo-text\",limit=18)\n",
    "teamsList = []\n",
    "for i in runnercountryHtml:\n",
    "    teamsList.append(i.text)\n",
    "batsmenTeamsList=teamsList[:9]\n",
    "for i in batsmenTeamsList:\n",
    "    batsmenTeamArr.append(i)\n",
    "# batsmenNameArr\n",
    "bowlersTeamsList=teamsList[9:18]\n",
    "for i in bowlersTeamsList:\n",
    "    bowlerTeamArr.append(i)\n",
    "runnerRatingHtml = soup.find_all('td',class_=\"table-body__cell u-text-right rating\",limit=18)\n",
    "runnerRatingList = []\n",
    "for i in runnerRatingHtml:\n",
    "    runnerRatingList.append(i.text)\n",
    "batsmenRatingList=runnerRatingList[:9]\n",
    "for i in batsmenRatingList:\n",
    "    batsmenRatingArr.append(i)\n",
    "# batsmenNameArr\n",
    "bowlersRatingList=runnerRatingList[9:18]\n",
    "for i in bowlersRatingList:\n",
    "    bowlerRatingArr.append(i)\n",
    "womenBatsmenFrame = pd.DataFrame({})\n",
    "womenBowlerFrame = pd.DataFrame({})\n",
    "womenBatsmenFrame['Player'] = batsmenNameArr\n",
    "womenBatsmenFrame['Team'] = batsmenTeamArr\n",
    "womenBatsmenFrame['Rating'] = batsmenRatingArr\n",
    "womenBowlerFrame['Player'] = bowlerNameArr\n",
    "womenBowlerFrame['Team'] = bowlerTeamArr\n",
    "womenBowlerFrame['Rating'] = bowlerRatingArr\n",
    "womenBatsmenFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oppo A31</td>\n",
       "      <td>₹11,490</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61IhTtJUXJ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>₹15,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmi 9A</td>\n",
       "      <td>₹8,799</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oppo A31</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy M31</td>\n",
       "      <td>₹6,799</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Redmi 9 Power</td>\n",
       "      <td>₹8,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61LHaUOheh...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy M11</td>\n",
       "      <td>₹11,490</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71GQUxuSpn...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy M01 Core</td>\n",
       "      <td>₹15,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71AYb2AGHX...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Product Name    Price  \\\n",
       "0                 Oppo A31  ₹11,490   \n",
       "1                  Redmi 9  ₹15,990   \n",
       "2                 Redmi 9A   ₹8,799   \n",
       "3                 Oppo A31  ₹10,999   \n",
       "4       Samsung Galaxy M31   ₹6,799   \n",
       "5            Redmi 9 Power   ₹8,499   \n",
       "6       Samsung Galaxy M11  ₹11,490   \n",
       "7  Samsung Galaxy M01 Core  ₹15,990   \n",
       "\n",
       "                                               Image              Rating  \n",
       "0  https://m.media-amazon.com/images/I/61IhTtJUXJ...  4.2 out of 5 stars  \n",
       "1  https://m.media-amazon.com/images/I/71A9Vo1Bat...  4.2 out of 5 stars  \n",
       "2  https://m.media-amazon.com/images/I/71sxlhYhKW...  4.2 out of 5 stars  \n",
       "3  https://m.media-amazon.com/images/I/71KCwNV6Mu...  4.2 out of 5 stars  \n",
       "4  https://m.media-amazon.com/images/I/71-Su4Wr0H...  4.3 out of 5 stars  \n",
       "5  https://m.media-amazon.com/images/I/61LHaUOheh...  4.2 out of 5 stars  \n",
       "6  https://m.media-amazon.com/images/I/71GQUxuSpn...  4.2 out of 5 stars  \n",
       "7  https://m.media-amazon.com/images/I/71AYb2AGHX...  3.7 out of 5 stars  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data \n",
    "# should include Product Name, Price, Image URL and Average Rating\n",
    "link = 'https://www.amazon.in/s?k=mobiles+under+20000rs&crid=OS3AMRB2OT33&sprefix=mobiles+under+20000%2Caps%2C-1&ref=nb_sb_ss_ts-doa-p_1_16'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "phoneNameHtml = soup.find_all('span',class_=\"a-size-medium a-color-base a-text-normal\",limit = 8)\n",
    "phoneNameArr = []\n",
    "for i in phoneNameHtml:\n",
    "    nameAndSpecs = i.text\n",
    "    ignoreWord = nameAndSpecs.find('(')-1\n",
    "    name = nameAndSpecs[:ignoreWord]\n",
    "    phoneNameArr.append(name)\n",
    "phonePriceHtml = soup.find_all('span',class_=\"a-offscreen\",limit = 8)\n",
    "phonePriceArr = []\n",
    "for i in phonePriceHtml:\n",
    "    phonePriceArr.append(i.text)\n",
    "imgHtml = soup.find_all('img',class_=\"s-image\",limit = 8)\n",
    "imgarr = []\n",
    "for i in imgHtml:\n",
    "    imgarr.append(i['src'])\n",
    "ratingHtml = soup.find_all('span',class_=\"a-icon-alt\",limit = 8)\n",
    "ratingArr = []\n",
    "for i in ratingHtml:\n",
    "    ratingArr.append(i.text)\n",
    "amazonDataFrame = pd.DataFrame({})\n",
    "amazonDataFrame['Product Name'] = phoneNameArr\n",
    "amazonDataFrame['Price'] = phonePriceArr\n",
    "amazonDataFrame['Image'] = imgarr\n",
    "amazonDataFrame['Rating'] = ratingArr\n",
    "amazonDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Title</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Picostone</td>\n",
       "      <td>3 - 6.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>6 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>369 Zoss Waters</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Software Developer (Full-Stack - Rea...</td>\n",
       "      <td>SleekSky LLC</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Relationship Specialist</td>\n",
       "      <td>InPhase Power Technologies</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate Editor Engagement</td>\n",
       "      <td>Cactus Communications Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Management Consultant Associate</td>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>4.5 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Web Analytics Developer</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>4.99 - 5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Social Media Marketing Manager</td>\n",
       "      <td>The Test Tribe</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Social Media Marketing Associate</td>\n",
       "      <td>Glu Studios</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Development Manager (Digital Marketin...</td>\n",
       "      <td>Graygraph Technologies LLC</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>BookLeaf Publishing</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ravi Ladia &amp; Co</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Research Associate</td>\n",
       "      <td>Market Vistas Consumer Insights</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Assistant Coordinator - Tender Department</td>\n",
       "      <td>Global Source Trading LLC</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Customer Relationship Manager (Publishing Cons...</td>\n",
       "      <td>Blue Rose Publishers</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Executive Assistant To Director</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Learning Consultant - Sales</td>\n",
       "      <td>Geekster</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>School/Teacher Consultant</td>\n",
       "      <td>InfyBytes AI Labs Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Junior Recruiter</td>\n",
       "      <td>Radish Consultants Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Moxie.xyz</td>\n",
       "      <td>9 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Fullmoon Outdoor Web Solutions</td>\n",
       "      <td>4 - 4.2 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Order Processor</td>\n",
       "      <td>InspectHOA</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Nikulsan Technologies Private Limited</td>\n",
       "      <td>3.5 - 5 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>IQGateway</td>\n",
       "      <td>3.6 - 10 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3.3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Varenyam Placements</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>HealthPlix Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Inside Sales Associate</td>\n",
       "      <td>Wizklub Learning</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Fusion Engineering</td>\n",
       "      <td>4.5 - 5.25 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Junior MERN Stack Developer</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Education Innovation Manager</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>General Management Associate</td>\n",
       "      <td>Redwood Algorithms</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Content &amp; E-commerce Management Trainee</td>\n",
       "      <td>Blooprint Ecom Consulting</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>QuikieApps</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sales Support &amp; Operations Executive</td>\n",
       "      <td>SysCloud Technologies Private Limited</td>\n",
       "      <td>3 - 3.01 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>Medcords Healthcare Solution Private Limited</td>\n",
       "      <td>3 - 7 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Bagga Infrastructure Limited</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>8 Jul' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                     Business Development Executive    \n",
       "1                      Associate Front End Developer    \n",
       "2                          Corporate Sales Executive    \n",
       "3   Associate Software Developer (Full-Stack - Rea...   \n",
       "4                   Customer Relationship Specialist    \n",
       "5                        Associate Editor Engagement    \n",
       "6                    Management Consultant Associate    \n",
       "7                            Web Analytics Developer    \n",
       "8              Junior Social Media Marketing Manager    \n",
       "9            Junior Social Media Marketing Associate    \n",
       "10  Business Development Manager (Digital Marketin...   \n",
       "11                    Business Development Executive    \n",
       "12                                        Accountant    \n",
       "13                                Research Associate    \n",
       "14         Assistant Coordinator - Tender Department    \n",
       "15  Customer Relationship Manager (Publishing Cons...   \n",
       "16                   Executive Assistant To Director    \n",
       "17                       Learning Consultant - Sales    \n",
       "18                         School/Teacher Consultant    \n",
       "19                                  Junior Recruiter    \n",
       "20                                Software Developer    \n",
       "21     Business Development Executive (Inside Sales)    \n",
       "22                                     Web Developer    \n",
       "23                                   Order Processor    \n",
       "24                              Full Stack Developer    \n",
       "25                      Associate Software Developer    \n",
       "26                                 Reactjs Developer    \n",
       "27                              Full Stack Developer    \n",
       "28                    Business Development Executive    \n",
       "29                         Corporate Sales Associate    \n",
       "30                            Inside Sales Associate    \n",
       "31                              Mobile App Developer    \n",
       "32                       Junior MERN Stack Developer    \n",
       "33                      Education Innovation Manager    \n",
       "34                      General Management Associate    \n",
       "35           Content & E-commerce Management Trainee    \n",
       "36                                 Software Engineer    \n",
       "37              Sales Support & Operations Executive    \n",
       "38                                 Backend Developer    \n",
       "39                                        Accountant    \n",
       "\n",
       "                                      Company Title             CTC  \\\n",
       "0                                         Picostone     3 - 6.5 LPA   \n",
       "1                    AIMonk Labs Technology Limited       6 - 7 LPA   \n",
       "2                                   369 Zoss Waters       3 - 5 LPA   \n",
       "3                                      SleekSky LLC           4 LPA   \n",
       "4                        InPhase Power Technologies     3 - 3.5 LPA   \n",
       "5             Cactus Communications Private Limited       3 - 4 LPA   \n",
       "6                                 StrategyCo.Global     4.5 - 7 LPA   \n",
       "7                         DataVinci Private Limited    4.99 - 5 LPA   \n",
       "8                                    The Test Tribe       3 - 4 LPA   \n",
       "9                                       Glu Studios     3 - 3.6 LPA   \n",
       "10                       Graygraph Technologies LLC     3 - 4.5 LPA   \n",
       "11                              BookLeaf Publishing     3 - 3.6 LPA   \n",
       "12                                  Ravi Ladia & Co           3 LPA   \n",
       "13                  Market Vistas Consumer Insights    3 - 3.25 LPA   \n",
       "14                        Global Source Trading LLC           3 LPA   \n",
       "15                             Blue Rose Publishers     3 - 3.5 LPA   \n",
       "16                            Best Roadways Limited           3 LPA   \n",
       "17                                         Geekster     3 - 3.5 LPA   \n",
       "18                InfyBytes AI Labs Private Limited       3 - 4 LPA   \n",
       "19               Radish Consultants Private Limited       3 - 5 LPA   \n",
       "20                                        Moxie.xyz           9 LPA   \n",
       "21                                          GREedge        3.75 LPA   \n",
       "22                   Fullmoon Outdoor Web Solutions     4 - 4.2 LPA   \n",
       "23                                       InspectHOA           3 LPA   \n",
       "24            Nikulsan Technologies Private Limited     3.5 - 5 LPA   \n",
       "25                                        IQGateway    3.6 - 10 LPA   \n",
       "26          Startxlabs Technologies Private Limited       3 - 4 LPA   \n",
       "27  RavGins International Private Limited (Wobb.ai)     3.3 - 4 LPA   \n",
       "28                              Varenyam Placements       3 - 4 LPA   \n",
       "29          HealthPlix Technologies Private Limited       3 - 4 LPA   \n",
       "30                                 Wizklub Learning       3 - 6 LPA   \n",
       "31                               Fusion Engineering  4.5 - 5.25 LPA   \n",
       "32     DeepThought Edutech Ventures Private Limited       3 - 5 LPA   \n",
       "33     DeepThought Edutech Ventures Private Limited       3 - 5 LPA   \n",
       "34                               Redwood Algorithms       4 - 5 LPA   \n",
       "35                        Blooprint Ecom Consulting           3 LPA   \n",
       "36                                       QuikieApps       3 - 4 LPA   \n",
       "37            SysCloud Technologies Private Limited    3 - 3.01 LPA   \n",
       "38     Medcords Healthcare Solution Private Limited       3 - 7 LPA   \n",
       "39                     Bagga Infrastructure Limited    3 - 3.25 LPA   \n",
       "\n",
       "    Apply Date  \n",
       "0   19 Jul' 21  \n",
       "1   18 Jul' 21  \n",
       "2   18 Jul' 21  \n",
       "3   18 Jul' 21  \n",
       "4   18 Jul' 21  \n",
       "5   18 Jul' 21  \n",
       "6   18 Jul' 21  \n",
       "7   17 Jul' 21  \n",
       "8   17 Jul' 21  \n",
       "9   17 Jul' 21  \n",
       "10  17 Jul' 21  \n",
       "11  17 Jul' 21  \n",
       "12  16 Jul' 21  \n",
       "13  17 Jul' 21  \n",
       "14  16 Jul' 21  \n",
       "15  16 Jul' 21  \n",
       "16  17 Jul' 21  \n",
       "17  16 Jul' 21  \n",
       "18  16 Jul' 21  \n",
       "19  16 Jul' 21  \n",
       "20  15 Jul' 21  \n",
       "21  15 Jul' 21  \n",
       "22  15 Jul' 21  \n",
       "23  14 Jul' 21  \n",
       "24  14 Jul' 21  \n",
       "25  11 Jul' 21  \n",
       "26  11 Jul' 21  \n",
       "27  11 Jul' 21  \n",
       "28  11 Jul' 21  \n",
       "29  11 Jul' 21  \n",
       "30  11 Jul' 21  \n",
       "31  14 Jul' 21  \n",
       "32  15 Jul' 21  \n",
       "33  10 Jul' 21  \n",
       "34  10 Jul' 21  \n",
       "35   9 Jul' 21  \n",
       "36   9 Jul' 21  \n",
       "37   9 Jul' 21  \n",
       "38   9 Jul' 21  \n",
       "39   8 Jul' 21  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date.\n",
    "link = 'https://internshala.com/fresher-jobs'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titleHtml = soup.find_all('div',class_=\"heading_4_5 profile\")\n",
    "titleArr = []\n",
    "for i in titleHtml:\n",
    "    titleArr.append(i.text.replace('\\n',''))\n",
    "# link_display_like_text\n",
    "companyHtml = soup.find_all('a',class_=\"link_display_like_text\")\n",
    "companyArr = []\n",
    "for i in companyHtml:\n",
    "    companyArr.append(i.text.replace('\\n','').replace('  ',''))\n",
    "ctcHtml = soup.find_all('div',class_= \"item_body\")\n",
    "# ctcHtml\n",
    "ctcArr = []\n",
    "applyDateArr = []\n",
    "k=0\n",
    "for i in ctcHtml:\n",
    "    if (k+2)%3 == 0:\n",
    "        ctcArr.append(i.text.replace('\\n','').replace('  ',''))\n",
    "    if (k+1)%3 == 0:\n",
    "        applyDateArr.append(i.text)\n",
    "    k=k+1\n",
    "internshalaDataFrame = pd.DataFrame({})\n",
    "internshalaDataFrame['Job Title'] = titleArr\n",
    "internshalaDataFrame['Company Title'] = companyArr\n",
    "internshalaDataFrame['CTC'] = ctcArr\n",
    "internshalaDataFrame['Apply Date'] = applyDateArr\n",
    "internshalaDataFrame\n",
    "# phoneNameArr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overnight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly clear, with a low around 56. Southwest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sunny thenSunny andBreezy</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Sunny, with a high near 71. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly clear, with a low around 56. Breezy, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Sunny, with a high near 71. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SundayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Partly cloudy, with a low around 57. West sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Partly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Mostly sunny, with a high near 69. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MondayNight</td>\n",
       "      <td>Mostly Clearand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Partly cloudy, with a low around 58. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Mostly sunny, with a high near 69.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TuesdayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Partly cloudy, with a low around 58.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Period                        Short Description  Temperature  \\\n",
       "0      Overnight                             Mostly Clear   Low: 56 °F   \n",
       "1       Saturday                Sunny thenSunny andBreezy  High: 71 °F   \n",
       "2  SaturdayNight  Mostly Clearand Breezythen PartlyCloudy   Low: 56 °F   \n",
       "3         Sunday         Mostly Sunnythen Sunnyand Breezy  High: 71 °F   \n",
       "4    SundayNight                            Partly Cloudy   Low: 57 °F   \n",
       "5         Monday         Partly Sunnythen Sunnyand Breezy  High: 69 °F   \n",
       "6    MondayNight  Mostly Clearand Breezythen MostlyCloudy   Low: 58 °F   \n",
       "7        Tuesday                             Mostly Sunny  High: 69 °F   \n",
       "8   TuesdayNight                            Partly Cloudy   Low: 58 °F   \n",
       "\n",
       "                                         Description  \n",
       "0  Mostly clear, with a low around 56. Southwest ...  \n",
       "1  Sunny, with a high near 71. Breezy, with a wes...  \n",
       "2  Mostly clear, with a low around 56. Breezy, wi...  \n",
       "3  Sunny, with a high near 71. Breezy, with a wes...  \n",
       "4  Partly cloudy, with a low around 57. West sout...  \n",
       "5        Mostly sunny, with a high near 69. Breezy.   \n",
       "6      Partly cloudy, with a low around 58. Breezy.   \n",
       "7                 Mostly sunny, with a high near 69.  \n",
       "8               Partly cloudy, with a low around 58.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to extract information about the local weather from the National Weather Service website of USA, \n",
    "# https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city.\n",
    "# The data should include period, short description, temperature and description.\n",
    "link = 'https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YMyAQWgzY2z'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titleHtml = soup.find_all('p',class_=\"period-name\")\n",
    "titleArr = []\n",
    "for i in titleHtml:\n",
    "    titleArr.append(i.text.replace('\\n',''))\n",
    "tempLowHtml = soup.find_all('p',class_=\"temp temp-low\")\n",
    "tempLowArr = []\n",
    "for i in tempLowHtml:\n",
    "    tempLowArr.append(i.text.replace('\\n',''))\n",
    "tempHighHtml = soup.find_all('p',class_=\"temp temp-high\")\n",
    "tempHighArr = []\n",
    "for i in tempHighHtml:\n",
    "    tempHighArr.append(i.text.replace('\\n',''))\n",
    "tempArr = [None]*(len(tempLowArr)+len(tempHighArr))\n",
    "tempArr[::2] = tempLowArr\n",
    "tempArr[1::2] = tempHighArr\n",
    "shortDescHtml = soup.find_all('p',class_=\"short-desc\")\n",
    "shortDescArr = []\n",
    "for i in shortDescHtml:\n",
    "    shortDescArr.append(i.text.replace('\\n',''))\n",
    "longDescHtml = soup.find_all('div',class_=\"col-sm-10 forecast-text\",limit = 9)\n",
    "longDescArr = []\n",
    "for i in longDescHtml:\n",
    "    longDescArr.append(i.text.replace('\\n',''))\n",
    "# longDescArr\n",
    "tempDataFrame = pd.DataFrame({})\n",
    "tempDataFrame['Period'] = titleArr\n",
    "tempDataFrame['Short Description'] = shortDescArr\n",
    "tempDataFrame['Temperature'] = tempArr\n",
    "tempDataFrame['Description'] = longDescArr\n",
    "tempDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genere</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rose Code</td>\n",
       "      <td>Kate Quinn, Saskia Maarleveld</td>\n",
       "      <td>Audio / Fiction / Historical Fiction</td>\n",
       "      <td>\\n\\nBletchley Park, the mansion where Oxford d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Damage</td>\n",
       "      <td>Caitlin Wahrer</td>\n",
       "      <td>Mystery &amp; Suspense / Suspense</td>\n",
       "      <td>\\n\\nWith twists worthy of a season finale of “...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>★ Blackout</td>\n",
       "      <td>Dhonielle Clayton, Tiffany D. Jackson, Nic Sto...</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>\\n\\nIn Blackout, six of YA’s biggest superstar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>★ The Sweetness of Water</td>\n",
       "      <td>Nathan Harris</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>\\n\\nNathan Harris’ Civil War-set debut novel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Killing Hills</td>\n",
       "      <td>Chris Offutt</td>\n",
       "      <td>Fiction / Crime Fiction</td>\n",
       "      <td>\\n\\nWhile Old Man Tucker is out collecting gin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Book Title  \\\n",
       "0              The Rose Code   \n",
       "1                 The Damage   \n",
       "2                 ★ Blackout   \n",
       "3   ★ The Sweetness of Water   \n",
       "4          The Killing Hills   \n",
       "\n",
       "                                              Author  \\\n",
       "0                      Kate Quinn, Saskia Maarleveld   \n",
       "1                                     Caitlin Wahrer   \n",
       "2  Dhonielle Clayton, Tiffany D. Jackson, Nic Sto...   \n",
       "3                                      Nathan Harris   \n",
       "4                                       Chris Offutt   \n",
       "\n",
       "                                 Genere  \\\n",
       "0  Audio / Fiction / Historical Fiction   \n",
       "1         Mystery & Suspense / Suspense   \n",
       "2                       YA / YA Fiction   \n",
       "3          Fiction / Historical Fiction   \n",
       "4               Fiction / Crime Fiction   \n",
       "\n",
       "                                              Review  \n",
       "0  \\n\\nBletchley Park, the mansion where Oxford d...  \n",
       "1  \\n\\nWith twists worthy of a season finale of “...  \n",
       "2  \\n\\nIn Blackout, six of YA’s biggest superstar...  \n",
       "3  \\n\\nNathan Harris’ Civil War-set debut novel, ...  \n",
       "4  \\n\\nWhile Old Man Tucker is out collecting gin...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://bookpage.com/reviews'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titleHtml = soup.find_all('h4',class_=\"italic\",limit=5)\n",
    "titleArr = []\n",
    "for i in titleHtml:\n",
    "    titleArr.append(i.text.replace('\\n',''))\n",
    "authorHtml = soup.find_all('p',class_=\"sans bold\",limit=5)\n",
    "authorArr = []\n",
    "for i in authorHtml:\n",
    "    authorArr.append(i.text.replace('\\n',''))\n",
    "#genre-links hidden-phone\n",
    "genereHtml = soup.find_all('p',class_=\"genre-links hidden-phone\",limit=5)\n",
    "genereArr = []\n",
    "for i in genereHtml:\n",
    "    genereArr.append(i.text.replace('\\n',''))\n",
    "def getTheReviewByLink(Link):\n",
    "    page1 = requests.get(Link)\n",
    "    soup1 = BeautifulSoup(page1.content)\n",
    "    reviewHtml = soup1.find('div',class_=\"article-body\")\n",
    "    return reviewHtml.text\n",
    "#read-full\n",
    "reviewLinkHtml = soup.find_all('div',class_=\"read-full\",limit=5)\n",
    "reviewArr = []\n",
    "for i in reviewLinkHtml:\n",
    "    link1 = i.find('a')['href']\n",
    "    link = 'https://bookpage.com' + link1\n",
    "    review = getTheReviewByLink(link)\n",
    "    reviewArr.append(review)\n",
    "bookpageDataFrame = pd.DataFrame({})\n",
    "bookpageDataFrame['Book Title'] = titleArr\n",
    "bookpageDataFrame['Author'] = authorArr\n",
    "bookpageDataFrame['Genere'] = genereArr\n",
    "bookpageDataFrame['Review'] = reviewArr\n",
    "bookpageDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flat Title</th>\n",
       "      <th>Flat Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Prize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Hosa ...</td>\n",
       "      <td>Oxford English School</td>\n",
       "      <td>1,800 sqft</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Ear O...</td>\n",
       "      <td>Independent House, Near opposite to Sobha Sili...</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK For Sale  In Daadys Garden In Electronic...</td>\n",
       "      <td>Daadys Garden  Kammasandra Rd, Kammasandra, El...</td>\n",
       "      <td>2,600 sqft</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Sarja...</td>\n",
       "      <td>Independent House,  Shantipura Village , S.P L...</td>\n",
       "      <td>1,100 sqft</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Shikaripalya, near Shams ...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹20,060/Month</td>\n",
       "      <td>₹35 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House,  Krishna reddy layout-Near ...</td>\n",
       "      <td>2,500 sqft</td>\n",
       "      <td>₹1.43 Lacs/Month</td>\n",
       "      <td>₹2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, Dhruv Dhama LayoutNear Hedd...</td>\n",
       "      <td>2,400 sqft</td>\n",
       "      <td>₹51,583/Month</td>\n",
       "      <td>₹90 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Gopalan Gardenia...</td>\n",
       "      <td>Gopalan Gardenia  Gopalan gardenia, Veerasandr...</td>\n",
       "      <td>2,650 sqft</td>\n",
       "      <td>₹63,045/Month</td>\n",
       "      <td>₹1.1 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Konappana Agrahara, Near ...</td>\n",
       "      <td>1,120 sqft</td>\n",
       "      <td>₹28,657/Month</td>\n",
       "      <td>₹50 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK Flat  For Sale  In Heena Enclave In Elec...</td>\n",
       "      <td>Neeladri Nagar,Near Pioneer Sun Blossom</td>\n",
       "      <td>2,350 sqft</td>\n",
       "      <td>₹71,643/Month</td>\n",
       "      <td>₹1.25 Crores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Flat Title  \\\n",
       "0  4 BHK In Independent House  For Sale  In Hosa ...   \n",
       "1  4 BHK In Independent House  For Sale  In Ear O...   \n",
       "2  4 BHK For Sale  In Daadys Garden In Electronic...   \n",
       "3  4 BHK In Independent House  For Sale  In Sarja...   \n",
       "4          4 BHK Flat  For Sale  In Electronic City    \n",
       "5  4 BHK In Independent House  For Sale  In Elect...   \n",
       "6  4 BHK In Independent House  For Sale  In Elect...   \n",
       "7  4 BHK Apartment  For Sale  In Gopalan Gardenia...   \n",
       "8          4 BHK Flat  For Sale  In Electronic City    \n",
       "9  4 BHK Flat  For Sale  In Heena Enclave In Elec...   \n",
       "\n",
       "                                       Flat Location        Area  \\\n",
       "0                              Oxford English School  1,800 sqft   \n",
       "1  Independent House, Near opposite to Sobha Sili...  1,200 sqft   \n",
       "2  Daadys Garden  Kammasandra Rd, Kammasandra, El...  2,600 sqft   \n",
       "3  Independent House,  Shantipura Village , S.P L...  1,100 sqft   \n",
       "4  Standalone Building, Shikaripalya, near Shams ...  1,400 sqft   \n",
       "5  Independent House,  Krishna reddy layout-Near ...  2,500 sqft   \n",
       "6  Independent House, Dhruv Dhama LayoutNear Hedd...  2,400 sqft   \n",
       "7  Gopalan Gardenia  Gopalan gardenia, Veerasandr...  2,650 sqft   \n",
       "8  Standalone Building, Konappana Agrahara, Near ...  1,120 sqft   \n",
       "9            Neeladri Nagar,Near Pioneer Sun Blossom  2,350 sqft   \n",
       "\n",
       "           Location         Prize  \n",
       "0     ₹45,851/Month      ₹80 Lacs  \n",
       "1     ₹45,851/Month      ₹80 Lacs  \n",
       "2     ₹85,971/Month   ₹1.5 Crores  \n",
       "3     ₹40,120/Month      ₹70 Lacs  \n",
       "4     ₹20,060/Month      ₹35 Lacs  \n",
       "5  ₹1.43 Lacs/Month   ₹2.5 Crores  \n",
       "6     ₹51,583/Month      ₹90 Lacs  \n",
       "7     ₹63,045/Month   ₹1.1 Crores  \n",
       "8     ₹28,657/Month      ₹50 Lacs  \n",
       "9     ₹71,643/Month  ₹1.25 Crores  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0'\n",
    "page = requests.get(link)\n",
    "soup = BeautifulSoup(page.content)\n",
    "titleHtml = soup.find_all('h2',class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "titleArr = []\n",
    "for i in titleHtml:\n",
    "    titleArr.append(i.text)\n",
    "locationHtml = soup.find_all('div',class_=\"nb__2CMjv\")\n",
    "locationArr = []\n",
    "for i in locationHtml:\n",
    "    locationArr.append(i.text)\n",
    "emiPrizeAreaHtml = soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "emiArr = []\n",
    "areaArr = []\n",
    "prizeArr = []\n",
    "count = 0\n",
    "for i in emiPrizeAreaHtml:\n",
    "    if count%3 == 1:\n",
    "        emiArr.append(i.text)\n",
    "    if count%3 == 2:\n",
    "        prizeArr.append(i.text)\n",
    "    if count%3 == 0:\n",
    "        areaArr.append(i.text)\n",
    "    count = count +1\n",
    "noBrokerDataFrame = pd.DataFrame({})\n",
    "noBrokerDataFrame['Flat Title'] = titleArr\n",
    "noBrokerDataFrame['Flat Location'] = locationArr\n",
    "noBrokerDataFrame['Area'] = areaArr\n",
    "noBrokerDataFrame['Location'] = emiArr\n",
    "noBrokerDataFrame['Prize'] = prizeArr\n",
    "noBrokerDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
